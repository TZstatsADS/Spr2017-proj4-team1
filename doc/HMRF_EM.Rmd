---
title: "HMRFEM Model"
author: "Yuan Mei"
date: "4/07/2017"
output: pdf_document
---

## Step 0: Load the packages, specify directories

```{r}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(text2vec, dplyr, qlcMatrix, kernlab, knitr)
library("stringr")

setwd("~/Documents/GitHub/Spr2017-proj4-team1/data")
# here replace it with your own path or manually set it in RStudio
# to where this rmd file is located
```

## Step 1: Load and process the data
```{r}
#get author_id, paper_id, coauthor_list, paper_title, journal name
Adata.lib="~/Documents/GitHub/Spr2017-proj4-team1/data/nameset"
data.files=list.files(path=data.lib, "*.txt")
data.files
### remove "*.txt"
query.list=substring(data.files, 
                     1, nchar(data.files)-4)

query.list
## add a space
query.list=paste(substring(query.list, 1, 1), 
                 " ", 
                 substring(query.list, 
                           2, nchar(query.list)),
                 sep=""
)

query.list

# Write a function to get the list of author_id, paper_id, coauthor_list, paper_title, journal name

f.line.proc=function(lin, nam.query="."){
  
  # remove unwanted characters
  char_notallowed <- "\\@#$%^&?" 
  lin.str=str_replace(lin, char_notallowed, "")
  
  # get author id
  lin.str=strsplit(lin.str, "_")[[1]]
  author_id=as.numeric(lin.str[1])
  
  # get paper id
  lin.str=lin.str[2]
  paper_id=strsplit(lin.str, " ")[[1]][1]
  lin.str=substring(lin.str, nchar(paper_id)+1, nchar(lin.str))
  paper_id=as.numeric(paper_id)
  
  # get coauthor list
  lin.str=strsplit(lin.str, "<>")[[1]]
  coauthor_list=strsplit(lin.str[1], ";")[[1]]
  
  #print(lin.str)
  for(j in 1:length(coauthor_list)){
    if(nchar(coauthor_list[j])>0){
      nam = strsplit(coauthor_list[j], " ")[[1]]
      if(nchar(nam[1])>0){
        first.ini=substring(nam[1], 1, 1)
      }else{
        first.ini=substring(nam[2], 1, 1)
      }
    }
    last.name=nam[length(nam)]
    nam.str = paste(first.ini, last.name)
    coauthor_list[j]=nam.str
  }
  
  match_ind = charmatch(nam.query, coauthor_list, nomatch=-1)
  
  #print(nam.query)
  #print(coauthor_list)
  #print(match_ind)
  
  if(match_ind>0){
    
    coauthor_list=coauthor_list[-match_ind]
  }
  
  paper_title=lin.str[2]
  journal_name=lin.str[3]
  
  list(author_id=author_id, 
       paper_id=paper_id, 
       coauthor_list=coauthor_list, 
       paper_title=paper_title, 
       journal_name=journal_name)
}

#read data
data_list=list(1:length(data.files))

for(i in 1:length(data.files)){
  
  dat=as.list(readLines(paste(data.lib, data.files[i], sep="/")))
  data_list[[i]]=lapply(dat, f.line.proc, nam.query=query.list[i])
  
  
}
names(data_list)=query.list
```

## Step 2: Feature design
Let’s first create a vocabulary-based DTM. Here we collect unique terms from all documents and mark each of them with a unique ID using the  `create_vocabulary()` function. We use an iterator to create the vocabulary.
```{r}
it_train_list <- list(1:length(data.files))
vocab <- list(1:length(data.files))
for (j in 1:length(data.files)) {
  data_unlist <- unlist(data_list[[j]])
  paper_title<- as.vector(data_unlist[which(names(data_unlist)=="paper_title")])
  it_train_list[[j]] <- itoken(paper_title, 
             preprocessor = tolower, 
             tokenizer = word_tokenizer,
             ids = AKumar$PaperID,
             progressbar = FALSE)
vocab[[j]] <- create_vocabulary(it_train, stopwords = c("a", "an", "the", "in", "on",
                                                   "at", "of", "above", "under"))

vocab[[j]]
  
  
}
```

Here, we remove pre-defined stopwords, the words like “a”, “the”, “in”, “I”, “you”, “on”, etc, which do not provide much useful information. 

Now that we have a vocabulary list, we can construct a document-term matrix.
```{r}
#construct DTM
vectorizer <- list(1:length(data.files))
dtm_train <- list(1:length(data.files))
for(i in 1:length(data.files)){
  vectorizer[[i]] <- vocab_vectorizer(vocab[[i]])
  dtm_train[[i]] <- create_dtm(it_train_list[[i]], vectorizer[[i]])
}

```

Now we have DTM and can check its dimensions.
```{r}
for (i in 1:length(data.files)){
print(dim(dtm_train[[i]]))
}
```


Then, we want to use DTM to compute TF-IDF transformation on DTM.
```{r}
dtm_train_tfidf  <- list(1:length(data.files))

for(i in 1:length(data.files)){
tfidf <- TfIdf$new()
dtm_train_tfidf[[i]] <- fit_transform(dtm_train[[i]], tfidf)
}

```

## Step 3: Write HMRFEM Algorithm

Construct Sets of must-link Constraints
```{r}
M <- list(1:length(data.files))
for (i in 1:length(data.files)){
  #calculate n and p
  n <- length(data_list[[i]])
  group <- data_list[[i]]
  coauthor_list <- vector(length=0)
  for(j in 1:n){
    coauthor_list_add <- group[[j]]$coauthor_list
    coauthor_list <-c(coauthor_list,coauthor_list_add)
  }
  coauthor_list <- unique(coauthor_list)
  p <- length(coauthor_list)
  
  #construct submatrix
  Mp <- diag(n)
  
  
  
}

```

Objective Function 
```{r}

```

Hmrf-em algorith
```{r}
```


## Step 4: Clustering
```{r}
```

## Step 5: Evaluation

To evaluate the performance of the method, it is required to calculate the degree of agreement between a set of system-output partitions and a set of true partitions. In general, the agreement between two partitioins is measured for a pair of entities within partitions. The basic unit for which pair-wise agreement is assessed is a pair of entities (authors in our case) which belongs to one of the four cells in the following table (Kang et at.(2009)):

\includegraphics[width=500pt]{matching_matrix.png}

Let $M$ be the set of machine-generated clusters, and $G$ the set of gold standard clusters. Then. in the table, for example, $a$ is the number of pairs of entities that are assigned to the same cluster in each of $M$ and $G$. Hence, $a$ and $d$ are interpreted as agreements, and $b$ and $c$ disagreements. When the table is considered as a confusion matrix for a two-class prediction problem, the standard "Precision", "Recall","F1", and "Accuracy" are defined as follows.

$$
\begin{aligned}
\mbox{Precision} &=\frac{a}{a+b}\\
\mbox{Recall}&=\frac{a}{a+c}\\
\mbox{F1} &=\frac{2\times\mbox{Precision}\times\mbox{Recall}}{\mbox{Precision}+\mbox{Recall}}\\
\mbox{Accuracy}&=\frac{a+d}{a+b+c+d}
\end{aligned}
$$

```{r}
source('~/Dropbox/Project4_WhoIsWho/lib/evaluation_measures.R')
matching_matrix_hclust <- matching_matrix(AKumar$AuthorID,result_hclust)
performance_hclust <- performance_statistics(matching_matrix_hclust)
matching_matrix_sclust <- matching_matrix(AKumar$AuthorID,result_sclust)
performance_sclust <- performance_statistics(matching_matrix_sclust)
compare_df <- data.frame(method=c("sClust","hClust"),
                         precision=c(performance_sclust$precision, performance_hclust$precision),
                         recall=c(performance_sclust$recall, performance_hclust$recall),
                         f1=c(performance_sclust$f1, performance_hclust$f1),
                         accuracy=c(performance_sclust$accuracy, performance_hclust$accuracy),
                         time=c(time_sclust,time_hclust))
kable(compare_df,caption="Comparision of performance for two clustering methods",digits = 2)
```


---
title: "test.coauthor"
date: "April 11, 2017"
output: html_document
---

```{r setup, include=FALSE}
data.lib="../data/nameset"
data.files=list.files(path=data.lib, "*.txt")

data.files

## remove "*.txt"
query.list=substring(data.files, 
                     1, nchar(data.files)-4)

query.list

## add a space
 query.list=paste(substring(query.list, 1, 1),
                " ",
                 substring(query.list,
                            2, nchar(query.list)),
                  sep=""
 )

 query.list

```

```{r}

f.line.proc=function(lin, nam.query="."){
  
  # remove unwanted characters
  char_notallowed <- "\\@#$%^&?" # characters to be removed
  lin.str=str_replace(lin, char_notallowed, "")
  
  # get author id
  lin.str=strsplit(lin.str, "_")[[1]]
  author_id=as.numeric(lin.str[1])
  
  # get paper id
  lin.str=lin.str[2]
  paper_id=strsplit(lin.str, " ")[[1]][1]
  lin.str=substring(lin.str, nchar(paper_id)+1, nchar(lin.str))
  paper_id=as.numeric(paper_id)
  
  # get coauthor list
  lin.str=strsplit(lin.str, "<>")[[1]]
  coauthor_list=strsplit(lin.str[1], ";")[[1]]
  
  #print(lin.str)
  for(j in 1:length(coauthor_list)){
    #print (nchar(coauthor_list[j]))
    #if (is.na(coauthor_list[j])==TRUE){
     # next
    #}
    if(nchar(coauthor_list[j])>0){
      nam = strsplit(coauthor_list[j], " ")[[1]]
      if(nchar(nam[1])>0){
        first.ini=substring(nam[1], 1, 1)
      }else{
        first.ini=substring(nam[2], 1, 1)
      }
    }
    last.name=nam[length(nam)]
    nam.str = paste(first.ini, last.name)
    coauthor_list[j]=nam.str
  }
  
  match_ind = charmatch(nam.query, coauthor_list, nomatch=-1)
  
  #print(nam.query)
  #print(coauthor_list)
  #print(match_ind)
  
  if(match_ind>0){
    
    coauthor_list=coauthor_list[-match_ind]
  }
  
  paper_title=lin.str[2]
  journal_name=lin.str[3]
  
  list(author_id, 
       paper_id, 
       coauthor_list, 
       paper_title, 
       journal_name)
}

```

```{r}
data_list=list(1:length(data.files))

for(i in 1:length(data.files)){
  
  ## Step 0 scan in one line at a time.
  

  dat=as.list(readLines(paste(data.lib, data.files[i], sep="/")))
  data_list[[i]]=lapply(dat, f.line.proc, nam.query=query.list[i])
  
  
}

```

```{r}

coauthor <- c()

#gsub(" ", "", ) 

for (i in 1:244){
coauthor <- c(coauthor, gsub(" ","", paste(data_list[[2]][[i]][[3]], collapse = "; ")))
} 
authorid <- c()
for (i in 1:244){
authorid <- c(authorid, paste(data_list[[2]][[i]][[1]], collapse = "; "))
} 

df_coauthor <- data.frame( 
                 Coauthor=character(244),
                 authorId=integer(244),
                 paperId=seq(1,244,1),
                 stringsAsFactors=FALSE) 
df_coauthor$Coauthor <- coauthor
df_coauthor$authorId <- authorid
```

```{r}
it_train_coauthor <- itoken(df_coauthor$Coauthor, 
                   preprocessor = tolower, 
                   tokenizer = word_tokenizer,
                   ids = df_coauthor$paperId ,
                   # turn off progressbar because it won't look nice in rmd
                   progressbar = FALSE)
vocab_coauthor <- create_vocabulary(it_train_coauthor, stopwords = c("a", "an", "the", "in", "on",
                                                   "at", "of", "above", "under"))

vectorizer_coauthor <- vocab_vectorizer(vocab_coauthor)
dtm_train_coauthor <- create_dtm(it_train_coauthor, vectorizer_coauthor)

tfidf_coauthor <- TfIdf$new()
dtm_train_tfidf_coauthor <- fit_transform(dtm_train_coauthor, tfidf_coauthor)

dim(dtm_train_tfidf_coauthor)

# AKumar$PaperID <- as.numeric(AKumar$PaperID)
# AKumar$AuthorID <- as.numeric(AKumar$AuthorID)



per_train <- 0.8 # percentage of training data
smp_size <- floor(per_train * nrow(df_coauthor)) # size of the sample
index <- sample(seq_len(nrow(df_coauthor)), size = smp_size)

# # numbers of AuthorIDs
# authorid<- length(table(AKumar$AuthorID))
# #training size of each AuthorID, take around 50%
# samplesize<-ceiling(table(AKumar$AuthorID)/2)
# #index for the training
# index<-NULL
# for (i in 1:authorid){
#   index<-c(index,sample(AKumar$PaperID[AKumar$AuthorID == i], size = samplesize[i]))
# }


 df_coauthor$authorId <- factor(df_coauthor$authorId)

x.train_coauthor<-dtm_train_tfidf_coauthor[index,]
x.test_coauthor<-dtm_train_tfidf_coauthor[-index,]
y.train_coauthor<-df_coauthor[index,]$authorId
y.test_coauthor<-df_coauthor[-index,]$authorId

# model<- svm(x = x.train, y = y.train,cost = 222,gamma = 0.1,cross = 5)
# pred<-predict(model,x.test)
# mean(pred == y.test)



#Cross Validation
# cost.list<- c(0.1,1,10,100,1000)
# gamma.list<- seq(0.1,1,0.1)
# error<-matrix(NA,nrow = length(gamma.list),ncol = length(cost.list))
# test.sd<-matrix(NA,nrow = length(gamma.list),ncol = length(cost.list))
# for (i in 1:length(cost.list)) {
#   for (j in 1:length(gamma.list) ) {
#     model<- svm(x = x.train, y = y.train,cost = i,gamma = j)
#     pred<-predict(model,x.test)
#     mean(pred == y.test)
# 
#     error[j,i]<- as.numeric(crossvalid$evaluation_log[crossvalid$best_iteration,4])
#   }
# }

cost.list<-c(0.1,1,10,20,30,40,50,60,70,80,90,100,200,300,1000)
gamma.list<- c(seq(0.1,1,0.1),2,5,9,20)

svm_tune_coauthor <- tune(svm, train.x=x.train_coauthor, train.y=y.train_coauthor, kernel="radial",
                  ranges=list(cost =c(0.1,1,10,20,30,40,50,60,70,80,90,100,200,300,1000),
                              gamma=c(seq(0.1,1,0.1),2,5,9,20)))


per_coauthor<-svm_tune_coauthor$performance
best_mar_coauthor<-per_coauthor$cost[which.min(per_coauthor$error)] 
best_gam_coauthor<-per_coauthor$gamma[which.min(per_coauthor$error)] 
best_mar_coauthor;best_gam_coauthor

pre_coauthor<-predict(svm_tune_coauthor$best.model,x.test_coauthor)
confusionMatrix(pre_coauthor,y.test_coauthor)

```

